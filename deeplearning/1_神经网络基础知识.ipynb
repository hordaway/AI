{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection  import train_test_split\n",
    "from matplotlib import pyplot as plt "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 梯度求解\n",
    "1.w声明为变量才可以被更新  \n",
    "2.loss函数最好是个凸函数  \n",
    "3.学习率太大会引起损失函数的来回波动，太小会影响求解速度\n",
    "4.了解下批量梯度下降和随机梯度下降，从性能上坐下比较"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "经过 1 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 3 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 4 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 5 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 6 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 7 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 8 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 9 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 10 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 11 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 12 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 13 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 14 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 15 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 16 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 17 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 18 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 19 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 20 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 21 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 22 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 23 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 24 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 25 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 26 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 27 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 28 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 29 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 30 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 31 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 32 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 33 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 34 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 35 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 36 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 37 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 38 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 39 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 40 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 41 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 42 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 43 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 44 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 45 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 46 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 47 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 48 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 49 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 50 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 51 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 52 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 53 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 54 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 55 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 56 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 57 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 58 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 59 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 60 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 61 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 62 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 63 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 64 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 65 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 66 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 67 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 68 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 69 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 70 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 71 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 72 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 73 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 74 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 75 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 76 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 77 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 78 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 79 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 80 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 81 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 82 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 83 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 84 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 85 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 86 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 87 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 88 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 89 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 90 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 91 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 92 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 93 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 94 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 95 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 96 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 97 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 98 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 99 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 100 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 101 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 102 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 103 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 104 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 105 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 106 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 107 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 108 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 109 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 110 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 111 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 112 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 113 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 114 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 115 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 116 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 117 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 118 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 119 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 120 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 121 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 122 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 123 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 124 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 125 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 126 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 127 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 128 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 129 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 130 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 131 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 132 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 133 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 134 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 135 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 136 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 137 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 138 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 139 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 140 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 141 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 142 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 143 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 144 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 145 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 146 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 147 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 148 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 149 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 150 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 151 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 152 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 153 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 154 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 155 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 156 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 157 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 158 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 159 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 160 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 161 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 162 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 163 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 164 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 165 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 166 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 167 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 168 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 169 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 170 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 171 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 172 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 173 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 174 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 175 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 176 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 177 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "经过 178 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 179 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 180 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 181 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 182 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 183 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 184 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 185 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 186 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 187 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 188 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 189 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 190 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 191 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 192 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 193 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 194 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 195 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 196 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 197 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 198 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 199 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 200 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 201 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 202 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 203 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 204 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 205 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 206 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 207 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 208 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 209 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 210 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 211 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 212 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 213 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 214 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 215 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 216 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 217 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 218 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 219 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 220 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 221 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 222 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 223 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 224 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 225 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 226 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 227 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 228 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 229 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 230 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 231 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 232 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 233 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 234 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 235 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 236 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 237 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 238 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 239 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 240 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 241 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 242 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 243 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 244 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 245 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 246 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 247 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 248 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 249 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 250 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 251 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 252 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 253 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 254 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 255 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 256 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 257 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 258 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 259 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 260 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 261 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 262 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 263 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 264 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 265 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 266 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 267 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 268 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 269 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 270 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 271 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 272 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 273 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 274 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 275 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 276 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 277 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 278 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 279 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 280 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 281 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 282 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 283 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 284 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 285 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 286 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 287 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 288 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 289 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 290 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 291 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 292 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 293 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 294 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 295 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 296 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 297 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 298 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 299 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 300 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 301 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 302 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 303 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 304 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 305 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 306 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 307 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 308 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 309 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 310 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 311 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 312 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 313 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 314 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 315 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 316 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 317 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 318 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 319 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 320 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 321 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 322 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 323 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 324 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 325 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 326 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 327 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 328 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 329 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 330 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 331 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 332 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 333 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 334 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 335 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 336 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 337 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 338 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 339 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 340 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 341 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 342 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 343 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 344 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 345 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 346 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 347 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 348 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 349 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 350 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 351 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 352 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 353 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 354 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 355 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 356 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 357 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 358 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 359 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 360 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 361 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 362 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 363 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 364 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 365 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 366 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 367 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 368 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 369 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 370 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 371 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 372 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 373 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "经过 374 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 375 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 376 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 377 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 378 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 379 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 380 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 381 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 382 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 383 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 384 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 385 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 386 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 387 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 388 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 389 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 390 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 391 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 392 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 393 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 394 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 395 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 396 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 397 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 398 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 399 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 400 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 401 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 402 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 403 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 404 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 405 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 406 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 407 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 408 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 409 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 410 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 411 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 412 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 413 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 414 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 415 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 416 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 417 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 418 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 419 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 420 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 421 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 422 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 423 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 424 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 425 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 426 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 427 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 428 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 429 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 430 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 431 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 432 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 433 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 434 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 435 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 436 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 437 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 438 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 439 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 440 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 441 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 442 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 443 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 444 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 445 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 446 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 447 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 448 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 449 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 450 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 451 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 452 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 453 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 454 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 455 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 456 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 457 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 458 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 459 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 460 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 461 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 462 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 463 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 464 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 465 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 466 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 467 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 468 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 469 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 470 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 471 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 472 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 473 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 474 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 475 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 476 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 477 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 478 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 479 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 480 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 481 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 482 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 483 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 484 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 485 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 486 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 487 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 488 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 489 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 490 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 491 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 492 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 493 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 494 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 495 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 496 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 497 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 498 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 499 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 500 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 501 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 502 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 503 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 504 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 505 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 506 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 507 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 508 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 509 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 510 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 511 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 512 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 513 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 514 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 515 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 516 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 517 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 518 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 519 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 520 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 521 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 522 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 523 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 524 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 525 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 526 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 527 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 528 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 529 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 530 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 531 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 532 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 533 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 534 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 535 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 536 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 537 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 538 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 539 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 540 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 541 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 542 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 543 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 544 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 545 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 546 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 547 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 548 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 549 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 550 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 551 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 552 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 553 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 554 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 555 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 556 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 557 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 558 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 559 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 560 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 561 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 562 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 563 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 564 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 565 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 566 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 567 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 568 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 569 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 570 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 571 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "经过 572 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 573 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 574 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 575 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 576 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 577 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 578 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 579 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 580 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 581 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 582 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 583 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 584 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 585 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 586 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 587 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 588 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 589 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 590 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 591 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 592 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 593 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 594 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 595 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 596 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 597 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 598 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 599 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 600 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 601 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 602 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 603 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 604 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 605 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 606 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 607 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 608 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 609 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 610 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 611 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 612 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 613 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 614 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 615 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 616 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 617 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 618 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 619 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 620 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 621 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 622 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 623 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 624 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 625 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 626 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 627 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 628 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 629 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 630 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 631 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 632 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 633 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 634 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 635 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 636 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 637 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 638 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 639 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 640 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 641 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 642 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 643 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 644 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 645 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 646 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 647 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 648 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 649 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 650 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 651 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 652 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 653 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 654 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 655 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 656 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 657 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 658 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 659 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 660 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 661 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 662 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 663 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 664 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 665 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 666 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 667 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 668 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 669 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 670 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 671 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 672 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 673 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 674 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 675 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 676 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 677 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 678 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 679 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 680 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 681 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 682 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 683 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 684 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 685 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 686 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 687 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 688 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 689 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 690 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 691 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 692 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 693 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 694 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 695 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 696 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 697 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 698 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 699 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 700 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 701 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 702 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 703 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 704 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 705 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 706 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 707 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 708 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 709 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 710 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 711 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 712 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 713 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 714 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 715 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 716 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 717 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 718 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 719 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 720 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 721 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 722 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 723 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 724 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 725 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 726 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 727 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 728 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 729 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 730 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 731 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 732 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 733 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 734 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 735 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 736 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 737 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 738 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 739 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 740 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 741 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 742 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 743 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 744 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 745 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 746 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 747 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 748 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 749 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 750 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 751 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 752 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 753 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 754 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 755 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 756 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 757 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 758 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 759 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 760 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 761 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 762 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 763 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 764 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 765 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "经过 766 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 767 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 768 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 769 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 770 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 771 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 772 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 773 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 774 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 775 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 776 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 777 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 778 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 779 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 780 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 781 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 782 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 783 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 784 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 785 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 786 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 787 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 788 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 789 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 790 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 791 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 792 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 793 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 794 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 795 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 796 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 797 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 798 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 799 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 800 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 801 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 802 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 803 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 804 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 805 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 806 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 807 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 808 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 809 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 810 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 811 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 812 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 813 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 814 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 815 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 816 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 817 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 818 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 819 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 820 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 821 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 822 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 823 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 824 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 825 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 826 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 827 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 828 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 829 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 830 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 831 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 832 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 833 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 834 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 835 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 836 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 837 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 838 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 839 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 840 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 841 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 842 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 843 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 844 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 845 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 846 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 847 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 848 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 849 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 850 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 851 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 852 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 853 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 854 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 855 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 856 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 857 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 858 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 859 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 860 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 861 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 862 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 863 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 864 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 865 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 866 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 867 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 868 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 869 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 870 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 871 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 872 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 873 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 874 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 875 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 876 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 877 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 878 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 879 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 880 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 881 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 882 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 883 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 884 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 885 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 886 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 887 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 888 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 889 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 890 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 891 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 892 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 893 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 894 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 895 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 896 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 897 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 898 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 899 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 900 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 901 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 902 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 903 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 904 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 905 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 906 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 907 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 908 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 909 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 910 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 911 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 912 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 913 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 914 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 915 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 916 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 917 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 918 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 919 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 920 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 921 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 922 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 923 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 924 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 925 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 926 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 927 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 928 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 929 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 930 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 931 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 932 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 933 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 934 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 935 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 936 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 937 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 938 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 939 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 940 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 941 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 942 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 943 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 944 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 945 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 946 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 947 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 948 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 949 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 950 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 951 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 952 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 953 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 954 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 955 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 956 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 957 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 958 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 959 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 960 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 961 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 962 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 963 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 964 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 965 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 966 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "经过 967 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 968 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 969 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 970 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 971 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 972 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 973 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 974 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 975 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 976 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 977 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 978 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 979 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 980 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 981 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 982 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 983 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 984 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 985 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 986 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 987 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 988 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 989 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 990 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 991 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 992 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 993 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 994 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 995 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 996 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 997 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 998 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 999 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1000 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1001 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1002 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1003 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1004 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1005 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1006 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1007 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1008 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1009 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1010 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1011 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1012 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1013 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1014 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1015 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1016 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1017 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1018 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1019 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1020 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1021 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1022 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1023 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1024 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1025 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1026 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1027 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1028 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1029 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1030 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1031 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1032 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1033 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1034 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1035 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1036 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1037 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1038 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1039 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1040 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1041 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1042 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1043 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1044 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1045 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1046 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1047 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1048 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1049 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1050 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1051 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1052 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1053 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1054 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1055 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1056 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1057 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1058 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1059 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1060 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1061 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1062 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1063 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1064 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1065 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1066 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1067 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1068 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1069 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1070 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1071 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1072 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1073 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1074 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1075 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1076 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1077 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1078 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1079 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1080 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1081 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1082 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1083 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1084 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1085 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1086 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1087 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1088 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1089 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1090 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1091 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1092 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1093 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1094 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1095 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1096 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1097 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1098 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1099 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1100 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1101 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1102 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1103 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1104 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1105 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1106 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1107 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1108 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1109 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1110 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1111 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1112 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1113 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1114 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1115 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1116 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1117 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1118 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1119 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1120 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1121 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1122 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1123 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1124 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1125 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1126 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1127 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1128 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1129 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1130 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1131 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1132 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1133 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1134 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1135 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1136 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1137 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1138 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1139 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1140 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1141 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1142 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1143 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1144 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1145 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1146 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1147 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1148 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1149 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1150 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1151 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1152 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1153 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1154 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "经过 1155 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1156 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1157 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1158 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1159 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1160 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1161 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1162 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1163 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1164 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1165 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1166 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1167 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1168 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1169 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1170 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1171 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1172 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1173 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1174 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1175 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1176 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1177 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1178 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1179 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1180 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1181 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1182 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1183 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1184 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1185 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1186 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1187 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1188 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1189 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1190 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1191 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1192 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1193 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1194 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1195 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1196 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1197 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1198 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1199 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1200 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1201 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1202 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1203 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1204 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1205 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1206 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1207 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1208 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1209 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1210 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1211 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1212 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1213 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1214 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1215 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1216 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1217 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1218 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1219 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1220 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1221 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1222 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1223 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1224 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1225 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1226 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1227 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1228 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1229 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1230 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1231 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1232 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1233 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1234 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1235 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1236 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1237 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1238 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1239 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1240 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1241 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1242 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1243 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1244 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1245 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1246 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1247 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1248 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1249 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1250 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1251 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1252 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1253 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1254 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1255 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1256 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1257 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1258 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1259 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1260 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1261 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1262 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1263 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1264 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1265 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1266 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1267 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1268 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1269 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1270 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1271 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1272 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1273 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1274 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1275 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1276 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1277 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1278 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1279 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1280 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1281 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1282 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1283 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1284 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1285 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1286 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1287 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1288 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1289 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1290 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1291 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1292 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1293 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1294 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1295 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1296 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1297 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1298 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1299 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1300 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1301 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1302 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1303 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1304 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1305 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1306 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1307 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1308 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1309 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1310 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1311 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1312 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1313 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1314 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1315 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1316 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1317 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1318 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1319 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1320 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1321 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1322 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1323 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1324 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1325 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1326 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1327 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1328 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1329 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1330 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1331 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1332 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1333 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1334 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1335 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1336 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1337 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1338 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1339 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1340 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1341 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1342 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1343 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1344 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1345 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1346 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1347 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1348 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "经过 1349 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1350 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1351 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1352 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1353 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1354 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1355 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1356 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1357 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1358 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1359 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1360 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1361 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1362 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1363 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1364 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1365 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1366 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1367 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1368 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1369 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1370 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1371 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1372 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1373 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1374 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1375 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1376 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1377 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1378 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1379 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1380 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1381 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1382 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1383 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1384 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1385 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1386 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1387 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1388 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1389 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1390 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1391 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1392 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1393 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1394 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1395 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1396 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1397 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1398 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1399 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1400 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1401 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1402 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1403 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1404 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1405 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1406 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1407 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1408 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1409 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1410 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1411 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1412 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1413 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1414 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1415 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1416 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1417 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1418 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1419 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1420 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1421 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1422 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1423 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1424 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1425 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1426 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1427 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1428 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1429 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1430 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1431 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1432 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1433 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1434 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1435 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1436 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1437 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1438 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1439 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1440 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1441 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1442 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1443 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1444 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1445 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1446 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1447 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1448 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1449 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1450 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1451 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1452 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1453 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1454 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1455 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1456 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1457 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1458 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1459 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1460 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1461 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1462 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1463 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1464 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1465 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1466 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1467 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1468 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1469 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1470 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1471 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1472 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1473 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1474 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1475 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1476 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1477 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1478 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1479 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1480 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1481 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1482 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1483 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1484 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1485 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1486 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1487 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1488 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1489 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1490 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1491 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1492 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1493 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1494 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1495 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1496 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1497 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1498 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1499 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1500 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1501 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1502 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1503 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1504 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1505 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1506 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1507 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1508 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1509 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1510 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1511 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1512 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1513 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1514 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1515 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1516 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1517 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1518 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1519 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1520 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1521 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1522 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1523 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1524 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1525 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "经过 1526 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1527 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1528 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1529 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1530 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1531 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1532 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1533 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1534 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1535 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1536 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1537 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1538 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1539 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1540 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1541 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1542 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1543 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1544 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1545 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1546 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1547 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1548 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1549 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1550 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1551 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1552 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1553 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1554 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1555 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1556 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1557 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1558 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1559 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1560 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1561 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1562 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1563 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1564 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1565 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1566 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1567 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1568 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1569 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1570 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1571 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1572 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1573 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1574 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1575 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1576 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1577 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1578 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1579 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1580 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1581 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1582 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1583 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1584 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1585 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1586 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1587 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1588 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1589 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1590 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1591 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1592 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1593 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1594 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1595 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1596 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1597 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1598 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1599 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1600 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1601 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1602 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1603 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1604 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1605 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1606 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1607 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1608 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1609 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1610 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1611 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1612 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1613 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1614 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1615 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1616 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1617 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1618 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1619 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1620 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1621 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1622 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1623 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1624 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1625 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1626 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1627 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1628 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1629 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1630 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1631 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1632 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1633 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1634 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1635 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1636 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1637 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1638 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1639 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1640 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1641 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1642 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1643 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1644 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1645 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1646 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1647 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1648 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1649 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1650 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1651 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1652 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1653 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1654 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1655 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1656 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1657 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1658 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1659 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1660 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1661 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1662 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1663 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1664 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1665 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1666 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1667 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1668 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1669 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1670 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1671 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1672 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1673 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1674 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1675 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1676 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1677 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1678 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1679 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1680 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1681 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1682 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1683 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1684 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1685 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1686 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1687 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1688 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1689 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1690 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1691 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1692 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1693 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1694 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1695 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1696 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1697 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1698 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1699 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1700 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "经过 1701 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1702 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1703 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1704 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1705 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1706 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1707 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1708 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1709 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1710 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1711 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1712 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1713 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1714 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1715 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1716 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1717 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1718 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1719 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1720 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1721 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1722 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1723 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1724 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1725 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1726 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1727 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1728 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1729 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1730 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1731 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1732 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1733 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1734 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1735 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1736 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1737 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1738 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1739 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1740 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1741 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1742 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1743 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1744 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1745 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1746 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1747 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1748 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1749 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1750 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1751 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1752 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1753 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1754 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1755 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1756 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1757 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1758 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1759 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1760 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1761 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1762 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1763 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1764 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1765 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1766 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1767 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1768 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1769 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1770 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1771 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1772 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1773 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1774 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1775 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1776 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1777 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1778 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1779 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1780 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1781 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1782 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1783 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1784 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1785 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1786 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1787 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1788 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1789 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1790 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1791 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1792 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1793 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1794 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1795 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1796 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1797 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1798 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1799 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1800 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1801 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1802 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1803 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1804 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1805 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1806 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1807 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1808 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1809 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1810 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1811 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1812 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1813 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1814 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1815 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1816 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1817 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1818 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1819 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1820 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1821 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1822 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1823 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1824 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1825 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1826 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1827 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1828 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1829 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1830 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1831 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1832 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1833 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1834 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1835 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1836 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1837 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1838 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1839 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1840 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1841 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1842 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1843 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1844 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1845 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1846 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1847 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1848 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1849 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1850 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1851 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1852 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1853 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1854 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1855 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1856 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1857 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1858 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1859 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1860 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1861 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1862 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1863 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1864 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1865 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1866 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1867 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1868 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1869 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1870 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1871 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1872 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1873 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1874 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1875 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1876 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1877 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1878 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1879 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1880 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1881 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1882 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1883 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1884 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1885 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1886 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1887 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1888 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1889 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1890 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "经过 1891 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1892 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1893 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1894 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1895 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1896 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1897 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1898 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1899 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1900 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1901 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1902 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1903 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1904 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1905 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1906 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1907 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1908 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1909 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1910 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1911 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1912 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1913 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1914 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1915 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1916 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1917 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1918 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1919 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1920 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1921 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1922 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1923 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1924 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1925 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1926 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1927 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1928 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1929 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1930 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1931 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1932 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1933 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1934 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1935 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1936 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1937 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1938 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1939 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1940 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1941 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1942 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1943 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1944 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1945 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1946 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1947 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1948 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1949 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1950 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1951 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1952 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1953 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1954 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1955 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1956 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1957 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1958 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1959 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1960 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1961 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1962 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1963 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1964 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1965 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1966 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1967 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1968 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1969 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1970 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1971 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1972 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1973 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1974 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1975 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1976 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1977 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1978 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1979 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1980 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1981 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1982 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1983 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1984 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1985 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1986 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1987 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1988 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1989 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1990 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1991 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1992 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1993 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1994 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1995 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1996 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1997 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 1998 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 1999 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2000 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2001 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2002 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2003 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2004 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2005 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2006 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2007 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2008 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2009 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2010 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2011 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2012 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2013 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2014 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2015 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2016 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2017 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2018 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2019 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2020 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2021 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2022 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2023 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2024 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2025 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2026 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2027 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2028 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2029 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2030 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2031 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2032 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2033 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2034 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2035 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2036 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2037 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2038 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2039 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2040 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2041 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2042 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2043 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2044 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2045 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2046 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2047 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2048 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2049 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2050 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2051 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2052 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2053 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2054 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2055 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2056 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2057 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2058 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2059 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2060 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2061 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2062 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2063 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2064 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2065 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2066 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2067 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2068 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2069 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2070 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2071 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2072 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2073 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2074 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2075 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2076 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2077 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2078 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2079 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2080 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2081 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "经过 2082 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2083 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2084 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2085 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2086 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2087 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2088 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2089 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2090 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2091 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2092 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2093 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2094 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2095 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2096 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2097 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2098 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2099 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2100 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2101 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2102 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2103 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2104 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2105 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2106 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2107 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2108 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2109 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2110 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2111 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2112 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2113 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2114 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2115 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2116 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2117 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2118 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2119 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2120 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2121 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2122 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2123 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2124 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2125 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2126 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2127 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2128 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2129 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2130 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2131 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2132 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2133 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2134 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2135 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2136 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2137 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2138 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2139 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2140 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2141 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2142 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2143 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2144 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2145 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2146 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2147 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2148 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2149 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2150 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2151 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2152 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2153 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2154 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2155 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2156 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2157 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2158 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2159 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2160 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2161 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2162 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2163 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2164 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2165 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2166 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2167 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2168 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2169 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2170 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2171 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2172 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2173 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2174 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2175 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2176 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2177 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2178 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2179 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2180 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2181 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2182 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2183 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2184 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2185 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2186 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2187 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2188 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2189 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2190 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2191 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2192 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2193 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2194 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2195 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2196 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2197 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2198 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2199 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2200 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2201 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2202 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2203 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2204 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2205 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2206 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2207 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2208 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2209 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2210 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2211 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2212 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2213 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2214 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2215 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2216 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2217 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2218 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2219 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2220 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2221 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2222 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2223 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2224 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2225 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2226 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2227 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2228 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2229 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2230 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2231 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2232 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2233 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2234 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2235 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2236 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2237 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2238 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2239 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2240 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2241 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2242 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2243 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2244 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2245 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2246 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2247 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2248 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2249 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2250 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2251 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2252 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2253 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2254 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2255 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2256 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2257 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2258 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2259 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2260 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2261 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2262 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2263 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2264 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2265 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2266 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2267 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2268 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2269 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2270 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2271 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2272 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2273 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2274 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "经过 2275 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2276 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2277 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2278 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2279 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2280 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2281 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2282 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2283 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2284 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2285 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2286 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2287 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2288 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2289 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2290 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2291 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2292 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2293 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2294 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2295 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2296 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2297 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2298 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2299 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2300 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2301 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2302 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2303 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2304 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2305 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2306 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2307 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2308 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2309 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2310 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2311 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2312 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2313 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2314 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2315 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2316 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2317 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2318 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2319 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2320 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2321 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2322 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2323 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2324 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2325 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2326 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2327 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2328 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2329 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2330 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2331 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2332 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2333 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2334 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2335 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2336 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2337 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2338 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2339 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2340 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2341 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2342 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2343 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2344 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2345 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2346 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2347 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2348 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2349 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2350 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2351 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2352 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2353 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2354 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2355 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2356 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2357 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2358 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2359 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2360 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2361 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2362 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2363 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2364 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2365 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2366 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2367 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2368 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2369 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2370 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2371 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2372 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2373 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2374 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2375 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2376 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2377 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2378 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2379 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2380 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2381 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2382 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2383 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2384 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2385 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2386 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2387 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2388 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2389 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2390 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2391 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2392 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2393 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2394 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2395 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2396 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2397 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2398 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2399 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2400 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2401 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2402 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2403 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2404 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2405 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2406 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2407 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2408 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2409 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2410 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2411 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2412 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2413 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2414 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2415 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2416 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2417 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2418 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2419 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2420 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2421 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2422 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2423 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2424 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2425 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2426 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2427 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2428 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2429 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2430 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2431 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2432 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2433 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2434 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2435 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2436 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2437 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "经过 2438 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2439 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2440 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2441 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2442 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2443 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2444 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2445 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2446 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2447 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2448 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2449 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2450 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2451 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2452 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2453 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2454 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2455 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2456 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2457 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2458 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2459 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2460 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2461 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2462 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2463 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2464 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2465 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2466 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2467 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2468 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2469 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2470 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2471 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2472 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2473 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2474 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2475 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2476 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2477 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2478 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2479 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2480 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2481 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2482 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2483 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2484 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2485 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2486 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2487 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2488 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2489 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2490 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2491 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2492 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2493 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2494 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2495 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2496 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2497 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2498 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2499 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2500 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2501 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2502 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2503 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2504 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2505 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2506 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2507 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2508 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2509 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2510 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2511 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2512 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2513 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2514 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2515 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2516 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2517 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2518 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2519 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2520 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2521 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2522 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2523 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2524 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2525 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2526 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2527 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2528 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2529 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2530 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2531 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2532 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2533 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2534 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2535 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2536 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2537 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2538 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2539 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2540 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2541 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2542 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2543 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2544 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2545 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2546 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2547 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2548 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2549 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2550 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2551 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2552 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2553 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2554 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2555 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2556 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2557 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2558 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2559 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2560 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2561 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2562 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2563 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2564 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2565 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2566 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2567 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2568 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2569 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2570 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2571 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2572 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2573 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2574 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2575 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2576 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2577 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2578 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2579 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2580 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2581 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2582 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2583 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2584 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2585 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2586 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2587 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2588 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2589 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2590 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2591 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2592 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2593 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2594 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2595 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2596 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2597 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2598 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2599 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2600 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2601 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2602 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2603 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2604 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2605 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2606 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2607 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2608 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2609 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2610 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2611 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2612 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2613 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2614 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2615 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2616 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2617 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2618 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2619 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2620 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "经过 2621 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2622 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2623 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2624 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2625 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2626 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2627 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2628 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2629 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2630 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2631 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2632 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2633 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2634 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2635 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2636 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2637 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2638 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2639 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2640 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2641 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2642 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2643 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2644 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2645 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2646 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2647 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2648 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2649 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2650 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2651 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2652 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2653 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2654 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2655 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2656 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2657 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2658 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2659 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2660 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2661 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2662 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2663 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2664 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2665 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2666 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2667 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2668 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2669 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2670 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2671 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2672 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2673 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2674 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2675 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2676 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2677 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2678 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2679 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2680 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2681 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2682 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2683 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2684 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2685 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2686 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2687 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2688 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2689 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2690 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2691 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2692 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2693 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2694 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2695 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2696 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2697 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2698 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2699 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2700 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2701 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2702 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2703 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2704 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2705 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2706 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2707 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2708 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2709 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2710 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2711 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2712 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2713 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2714 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2715 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2716 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2717 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2718 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2719 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2720 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2721 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2722 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2723 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2724 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2725 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2726 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2727 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2728 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2729 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2730 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2731 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2732 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2733 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2734 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2735 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2736 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2737 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2738 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2739 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2740 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2741 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2742 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2743 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2744 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2745 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2746 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2747 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2748 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2749 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2750 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2751 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2752 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2753 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2754 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2755 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2756 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2757 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2758 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2759 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2760 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2761 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2762 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2763 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2764 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2765 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2766 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2767 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2768 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2769 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2770 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2771 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2772 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2773 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2774 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2775 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2776 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2777 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2778 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2779 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2780 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2781 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2782 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2783 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2784 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2785 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2786 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2787 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2788 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2789 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2790 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2791 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2792 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2793 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2794 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2795 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2796 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2797 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2798 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2799 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2800 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2801 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2802 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2803 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2804 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2805 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2806 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2807 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2808 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2809 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2810 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2811 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2812 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2813 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2814 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2815 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2816 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2817 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "经过 2818 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2819 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2820 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2821 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2822 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2823 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2824 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2825 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2826 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2827 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2828 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2829 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2830 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2831 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2832 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2833 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2834 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2835 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2836 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2837 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2838 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2839 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2840 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2841 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2842 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2843 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2844 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2845 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2846 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2847 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2848 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2849 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2850 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2851 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2852 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2853 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2854 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2855 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2856 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2857 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2858 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2859 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2860 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2861 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2862 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2863 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2864 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2865 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2866 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2867 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2868 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2869 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2870 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2871 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2872 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2873 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2874 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2875 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2876 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2877 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2878 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2879 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2880 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2881 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2882 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2883 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2884 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2885 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2886 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2887 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2888 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2889 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2890 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2891 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2892 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2893 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2894 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2895 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2896 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2897 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2898 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2899 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2900 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2901 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2902 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2903 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2904 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2905 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2906 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2907 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2908 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2909 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2910 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2911 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2912 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2913 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2914 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2915 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2916 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2917 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2918 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2919 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2920 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2921 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2922 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2923 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2924 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2925 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2926 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2927 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2928 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2929 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2930 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2931 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2932 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2933 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2934 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2935 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2936 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2937 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2938 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2939 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2940 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2941 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2942 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2943 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2944 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2945 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2946 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2947 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2948 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2949 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2950 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2951 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2952 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2953 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2954 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2955 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2956 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2957 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2958 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2959 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2960 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2961 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2962 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2963 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2964 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2965 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2966 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2967 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2968 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2969 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2970 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2971 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2972 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2973 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2974 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2975 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2976 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2977 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2978 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2979 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2980 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2981 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2982 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2983 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2984 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2985 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2986 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2987 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2988 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2989 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2990 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2991 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2992 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2993 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2994 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2995 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2996 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2997 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 2998 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n",
      "经过 2999 轮后，梯度为 30.000000,权重w被更新为 -25.000000,损失函数减小到 225.000000 \n",
      "经过 3000 轮后，梯度为 -30.000000,权重w被更新为 5.000000,损失函数减小到 225.000000 \n"
     ]
    }
   ],
   "source": [
    "w = tf.Variable(tf.constant(5,dtype=tf.float32))\n",
    "lr = 1 ## 更换 99，0.9 0.5，0.1，0.001，0.0001 观察损失函数\n",
    "epochs = 3000\n",
    "\n",
    "for i in range(epochs):\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss = tf.square(w+10)\n",
    "    grads = tape.gradient(loss,w)\n",
    "    w.assign_sub(lr * grads)\n",
    "    print (\"经过 %s 轮后，梯度为 %f,权重w被更新为 %f,损失函数减小到 %f \" % (i+1,grads,w.numpy(),loss))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 变量申明"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 1)\n",
      "<dtype: 'float32'>\n",
      "tf.Tensor(\n",
      "[[1.]\n",
      " [5.]], shape=(2, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "a= tf.constant([[1],[5]],dtype=tf.float32)\n",
    "print(a.shape)    \n",
    "print(a.dtype)\n",
    "print (a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4]\n",
      "tf.Tensor([0 1 2 3 4], shape=(5,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "a = np.arange(0,5)\n",
    "tfa = tf.convert_to_tensor(a)\n",
    "print (a)\n",
    "print (tfa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1. 1. 1. 1. 1.]], shape=(5, 9), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0.]], shape=(7, 8), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[5 5 5 5 5 5 5]\n",
      " [5 5 5 5 5 5 5]\n",
      " [5 5 5 5 5 5 5]\n",
      " [5 5 5 5 5 5 5]\n",
      " [5 5 5 5 5 5 5]], shape=(5, 7), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "ones = tf.ones([5,9])\n",
    "zeros = tf.zeros([7,8])\n",
    "fives = tf.fill([5,7],5)\n",
    "\n",
    "print (ones)\n",
    "print (zeros)\n",
    "print (fives)"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  3.生成特定的数据分布\n",
    "1. 正态分布随机数  \n",
    "2. 正态分布，正负2个标准差之内  \n",
    "3. 在最小最大区间内均匀分布  \n",
    "4. 不同的参数W的分布情况对Y的求解影响很大，注意观察下激活函数的导数图像\n",
    "\n",
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[-1.7109015  -0.9300374  -0.66449136  0.9636723 ]\n",
      " [ 0.49803752 -1.5722955  -0.16649203  1.4287496 ]\n",
      " [-1.7965844   0.5195659   0.03994779  2.2865152 ]], shape=(3, 4), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[-0.10155702  0.0167294  -0.02351208 -0.03362651 -0.02222624 -0.03205836\n",
      "  -0.05127626 -0.0907651   0.02459155]\n",
      " [-0.09951223  0.01831531 -0.0068343  -0.00329791  0.04675551  0.11777903\n",
      "   0.14333369  0.10167997 -0.00617781]\n",
      " [ 0.03927894  0.11150867  0.00439592 -0.02477582 -0.01270446  0.08124328\n",
      "   0.13309798  0.13522618 -0.04118414]\n",
      " [ 0.19976576  0.04670754  0.09546791 -0.13951086 -0.19592302  0.03036319\n",
      "   0.04138457 -0.03900945 -0.0905342 ]\n",
      " [ 0.02287178  0.0326607  -0.15808521 -0.01598979  0.06733575 -0.05860201\n",
      "   0.07014062  0.04217517  0.09067583]], shape=(5, 9), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[0.46234286 0.4356258  0.4206711 ]\n",
      " [0.8243511  0.33325744 0.77966166]], shape=(2, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "a = tf.random.normal([3,4],mean=0,stddev=1)\n",
    "print (a)\n",
    "b = tf.random.truncated_normal([5,9],mean=0,stddev=0.1)\n",
    "print (b)\n",
    "c = tf.random.uniform([2,3],minval=0,maxval=1)\n",
    "print (c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. 运算相关\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[2.6415813 7.376336  9.409105  6.9249353 9.168931 ]\n",
      " [2.478602  0.5531287 2.7108383 6.579032  4.177228 ]], shape=(2, 5), dtype=float32)\n",
      "\n",
      "tf.Tensor(0.5531287, shape=(), dtype=float32)\n",
      "tf.Tensor(9.409105, shape=(), dtype=float32)\n",
      "tf.Tensor(5.201972, shape=(), dtype=float32)\n",
      "tf.Tensor(52.01972, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "x = tf.random.uniform([2,5],minval=0,maxval=10)\n",
    "x\n",
    "minX = tf.reduce_min(x)\n",
    "maxX = tf.reduce_max(x)\n",
    "meanX = tf.reduce_mean(x)\n",
    "sumX = tf.reduce_sum(x)\n",
    "print (x,end=\"\\n\\n\")\n",
    "print (minX)\n",
    "print (maxX)\n",
    "print (meanX)\n",
    "print (sumX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]], shape=(3, 4), dtype=float32) tf.Tensor(\n",
      "[[5. 5. 5. 5.]\n",
      " [5. 5. 5. 5.]\n",
      " [5. 5. 5. 5.]], shape=(3, 4), dtype=float32)\n",
      "a+b tf.Tensor(\n",
      "[[6. 6. 6. 6.]\n",
      " [6. 6. 6. 6.]\n",
      " [6. 6. 6. 6.]], shape=(3, 4), dtype=float32)\n",
      "a-b tf.Tensor(\n",
      "[[-4. -4. -4. -4.]\n",
      " [-4. -4. -4. -4.]\n",
      " [-4. -4. -4. -4.]], shape=(3, 4), dtype=float32)\n",
      "a*b tf.Tensor(\n",
      "[[5. 5. 5. 5.]\n",
      " [5. 5. 5. 5.]\n",
      " [5. 5. 5. 5.]], shape=(3, 4), dtype=float32)\n",
      "a/b tf.Tensor(\n",
      "[[0.2 0.2 0.2 0.2]\n",
      " [0.2 0.2 0.2 0.2]\n",
      " [0.2 0.2 0.2 0.2]], shape=(3, 4), dtype=float32)\n",
      "b的3次方 tf.Tensor(\n",
      "[[125. 125. 125. 125.]\n",
      " [125. 125. 125. 125.]\n",
      " [125. 125. 125. 125.]], shape=(3, 4), dtype=float32)\n",
      "b的平方 tf.Tensor(\n",
      "[[25. 25. 25. 25.]\n",
      " [25. 25. 25. 25.]\n",
      " [25. 25. 25. 25.]], shape=(3, 4), dtype=float32)\n",
      "b的开方 tf.Tensor(\n",
      "[[2.236068 2.236068 2.236068 2.236068]\n",
      " [2.236068 2.236068 2.236068 2.236068]\n",
      " [2.236068 2.236068 2.236068 2.236068]], shape=(3, 4), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "a = tf.fill([3,4],1.)\n",
    "b = tf.fill([3,4],5.)\n",
    "print (a,b)\n",
    "print (\"a+b\",tf.add(a,b))\n",
    "print (\"a-b\",tf.subtract(a,b))\n",
    "print (\"a*b\",tf.multiply(a,b))\n",
    "print (\"a/b\",tf.divide(a,b))\n",
    "print (\"b的3次方\",tf.pow(b,3))\n",
    "print (\"b的平方\",tf.square(b))\n",
    "print (\"b的开方\",tf.sqrt(b))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[1. 1.]\n",
      " [1. 1.]\n",
      " [1. 1.]], shape=(3, 2), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[3. 3. 3.]\n",
      " [3. 3. 3.]], shape=(2, 3), dtype=float32)\n",
      "矩阵乘法: tf.Tensor(\n",
      "[[6. 6. 6.]\n",
      " [6. 6. 6.]\n",
      " [6. 6. 6.]], shape=(3, 3), dtype=float32)\n",
      "矩阵乘法: tf.Tensor(\n",
      "[[6. 6. 6.]\n",
      " [6. 6. 6.]\n",
      " [6. 6. 6.]], shape=(3, 3), dtype=float32)\n",
      "矩阵乘法: tf.Tensor(\n",
      "[[6. 6. 6.]\n",
      " [6. 6. 6.]\n",
      " [6. 6. 6.]], shape=(3, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "a = tf.ones([3, 2])\n",
    "b = tf.fill([2, 3], 3.)\n",
    "print (a)\n",
    "print (b)\n",
    "print (\"矩阵乘法:\",tf.matmul(a,b))\n",
    "print (\"矩阵乘法:\",a@b )\n",
    "print (\"矩阵乘法:\", tf.convert_to_tensor(np.dot(a,b)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<tf.Tensor: shape=(), dtype=string, numpy=b'a'>, <tf.Tensor: shape=(), dtype=int32, numpy=1>)\n",
      "(<tf.Tensor: shape=(), dtype=string, numpy=b'b'>, <tf.Tensor: shape=(), dtype=int32, numpy=2>)\n",
      "(<tf.Tensor: shape=(), dtype=string, numpy=b'c'>, <tf.Tensor: shape=(), dtype=int32, numpy=3>)\n",
      "(<tf.Tensor: shape=(), dtype=string, numpy=b'd'>, <tf.Tensor: shape=(), dtype=int32, numpy=4>)\n",
      "(<tf.Tensor: shape=(), dtype=string, numpy=b'e'>, <tf.Tensor: shape=(), dtype=int32, numpy=5>)\n",
      "tf.Tensor(\n",
      "[[0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0.]], shape=(5, 5), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "features = tf.constant(['a','b','c','d','e'])\n",
    "labels = tf.constant([1,2,3,4,5])\n",
    "dataset = tf.data.Dataset.from_tensor_slices( (features,labels) )\n",
    "for element in dataset:\n",
    "    print (element)\n",
    "    \n",
    "output = tf.one_hot(labels,depth=5)\n",
    "\n",
    "print (output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. 分类问题的输出以概率表示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[ 1.0099998  2.008     -0.6600003]], shape=(1, 3), dtype=float32)\n",
      "tf.Tensor([0.2563381  0.69540703 0.04825489], shape=(3,), dtype=float32)\n",
      "tf.Tensor(1.0, shape=(), dtype=float32)\n",
      "tf.Tensor(0.69540703, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "x = tf.constant([[5.8, 4.0, 1.2, 0.2]]) ##  1*4\n",
    "w = tf.constant([[-0.8, -0.34, -1.4],  ## 4行3列，3个神经元\n",
    "                  [0.6, 1.3, 0.25],\n",
    "                  [0.5, 1.45, 0.9],\n",
    "                  [0.65, 0.7, -1.2]])\n",
    "b = tf.constant([2.52, -3.1, 5.62]) ## 3个偏置\n",
    "y = tf.matmul (x,w)+b\n",
    "print (y) ## 非概率\n",
    "y_dim = tf.squeeze(y)  # 去掉y中纬度1（观察y_dim与 y 效果对比）\n",
    "y_pro = tf.nn.softmax(y_dim)  # 使y_dim符合概率分布，输出为概率值了\n",
    "print(y_pro)\n",
    "print (tf.reduce_sum(y_pro))\n",
    "print (y_pro[tf.argmax(y_pro,axis=0)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.鸢尾花问题实战"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150\n",
      "(150, 4)\n",
      "(150,)\n"
     ]
    }
   ],
   "source": [
    "X = datasets.load_iris().data\n",
    "y = datasets.load_iris().target\n",
    "print (len(X))\n",
    "print (X.shape)\n",
    "print (y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_valid,y_train,y_valid = train_test_split(X,y,test_size=0.2,random_state=7)\n",
    "X_train = tf.cast(X_train, tf.float32)\n",
    "X_valid = tf.cast(X_valid, tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_db = tf.data.Dataset.from_tensor_slices((X_train,y_train)).batch(16)\n",
    "valid_db = tf.data.Dataset.from_tensor_slices((X_valid,y_valid)).batch(16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 (<tf.Tensor: shape=(16, 4), dtype=float32, numpy=\n",
      "array([[6.2, 2.8, 4.8, 1.8],\n",
      "       [5.7, 2.6, 3.5, 1. ],\n",
      "       [4.6, 3.6, 1. , 0.2],\n",
      "       [6.9, 3.1, 5.4, 2.1],\n",
      "       [6.4, 2.9, 4.3, 1.3],\n",
      "       [4.8, 3. , 1.4, 0.3],\n",
      "       [5.5, 3.5, 1.3, 0.2],\n",
      "       [5.4, 3.9, 1.7, 0.4],\n",
      "       [5.1, 3.5, 1.4, 0.3],\n",
      "       [7.1, 3. , 5.9, 2.1],\n",
      "       [6.7, 3.3, 5.7, 2.1],\n",
      "       [6.8, 2.8, 4.8, 1.4],\n",
      "       [6.4, 2.8, 5.6, 2.2],\n",
      "       [6.5, 3. , 5.5, 1.8],\n",
      "       [5.7, 3. , 4.2, 1.2],\n",
      "       [5. , 3.3, 1.4, 0.2]], dtype=float32)>, <tf.Tensor: shape=(16,), dtype=int32, numpy=array([2, 1, 0, 2, 1, 0, 0, 0, 0, 2, 2, 1, 2, 2, 1, 0])>)\n",
      "1 (<tf.Tensor: shape=(16, 4), dtype=float32, numpy=\n",
      "array([[6.7, 3.1, 4.4, 1.4],\n",
      "       [6. , 2.2, 4. , 1. ],\n",
      "       [6.4, 2.7, 5.3, 1.9],\n",
      "       [4.7, 3.2, 1.6, 0.2],\n",
      "       [4.6, 3.1, 1.5, 0.2],\n",
      "       [5.1, 3.4, 1.5, 0.2],\n",
      "       [7.7, 3.8, 6.7, 2.2],\n",
      "       [4.3, 3. , 1.1, 0.1],\n",
      "       [6.3, 3.3, 6. , 2.5],\n",
      "       [5.5, 2.4, 3.7, 1. ],\n",
      "       [5. , 2. , 3.5, 1. ],\n",
      "       [6.5, 2.8, 4.6, 1.5],\n",
      "       [5. , 3.4, 1.6, 0.4],\n",
      "       [4.4, 2.9, 1.4, 0.2],\n",
      "       [5. , 3.5, 1.6, 0.6],\n",
      "       [6.7, 3.1, 4.7, 1.5]], dtype=float32)>, <tf.Tensor: shape=(16,), dtype=int32, numpy=array([1, 1, 2, 0, 0, 0, 2, 0, 2, 1, 1, 1, 0, 0, 0, 1])>)\n",
      "2 (<tf.Tensor: shape=(16, 4), dtype=float32, numpy=\n",
      "array([[7.3, 2.9, 6.3, 1.8],\n",
      "       [5.5, 2.6, 4.4, 1.2],\n",
      "       [5.2, 2.7, 3.9, 1.4],\n",
      "       [5.7, 4.4, 1.5, 0.4],\n",
      "       [7.2, 3.2, 6. , 1.8],\n",
      "       [5.4, 3.4, 1.7, 0.2],\n",
      "       [5.8, 4. , 1.2, 0.2],\n",
      "       [6.1, 2.6, 5.6, 1.4],\n",
      "       [5.7, 2.5, 5. , 2. ],\n",
      "       [4.8, 3. , 1.4, 0.1],\n",
      "       [6.5, 3. , 5.8, 2.2],\n",
      "       [4.6, 3.2, 1.4, 0.2],\n",
      "       [6.6, 2.9, 4.6, 1.3],\n",
      "       [6.7, 3. , 5.2, 2.3],\n",
      "       [6.1, 3. , 4.6, 1.4],\n",
      "       [5.7, 3.8, 1.7, 0.3]], dtype=float32)>, <tf.Tensor: shape=(16,), dtype=int32, numpy=array([2, 1, 1, 0, 2, 0, 0, 2, 2, 0, 2, 0, 1, 2, 1, 0])>)\n",
      "3 (<tf.Tensor: shape=(16, 4), dtype=float32, numpy=\n",
      "array([[7. , 3.2, 4.7, 1.4],\n",
      "       [4.7, 3.2, 1.3, 0.2],\n",
      "       [6.5, 3. , 5.2, 2. ],\n",
      "       [7.7, 2.6, 6.9, 2.3],\n",
      "       [4.9, 2.4, 3.3, 1. ],\n",
      "       [4.8, 3.1, 1.6, 0.2],\n",
      "       [5.5, 4.2, 1.4, 0.2],\n",
      "       [5.6, 3. , 4.1, 1.3],\n",
      "       [6.4, 3.2, 5.3, 2.3],\n",
      "       [5.2, 3.5, 1.5, 0.2],\n",
      "       [7.9, 3.8, 6.4, 2. ],\n",
      "       [5.8, 2.8, 5.1, 2.4],\n",
      "       [5.7, 2.9, 4.2, 1.3],\n",
      "       [5.1, 3.7, 1.5, 0.4],\n",
      "       [5.1, 2.5, 3. , 1.1],\n",
      "       [5. , 3.4, 1.5, 0.2]], dtype=float32)>, <tf.Tensor: shape=(16,), dtype=int32, numpy=array([1, 0, 2, 2, 1, 0, 0, 1, 2, 0, 2, 2, 1, 0, 1, 0])>)\n",
      "4 (<tf.Tensor: shape=(16, 4), dtype=float32, numpy=\n",
      "array([[7.7, 2.8, 6.7, 2. ],\n",
      "       [7.6, 3. , 6.6, 2.1],\n",
      "       [5. , 3.2, 1.2, 0.2],\n",
      "       [5.4, 3.7, 1.5, 0.2],\n",
      "       [6.7, 3.3, 5.7, 2.5],\n",
      "       [6.1, 2.8, 4. , 1.3],\n",
      "       [6.3, 2.5, 5. , 1.9],\n",
      "       [7.4, 2.8, 6.1, 1.9],\n",
      "       [5. , 2.3, 3.3, 1. ],\n",
      "       [5.4, 3.4, 1.5, 0.4],\n",
      "       [5.4, 3.9, 1.3, 0.4],\n",
      "       [5.6, 2.8, 4.9, 2. ],\n",
      "       [4.9, 3. , 1.4, 0.2],\n",
      "       [5.3, 3.7, 1.5, 0.2],\n",
      "       [6. , 2.7, 5.1, 1.6],\n",
      "       [6.8, 3.2, 5.9, 2.3]], dtype=float32)>, <tf.Tensor: shape=(16,), dtype=int32, numpy=array([2, 2, 0, 0, 2, 1, 2, 2, 1, 0, 0, 2, 0, 0, 1, 2])>)\n",
      "5 (<tf.Tensor: shape=(16, 4), dtype=float32, numpy=\n",
      "array([[6.2, 3.4, 5.4, 2.3],\n",
      "       [5.7, 2.8, 4.1, 1.3],\n",
      "       [6.3, 2.3, 4.4, 1.3],\n",
      "       [4.9, 3.1, 1.5, 0.1],\n",
      "       [6.9, 3.1, 5.1, 2.3],\n",
      "       [5. , 3.6, 1.4, 0.2],\n",
      "       [4.4, 3. , 1.3, 0.2],\n",
      "       [6. , 2.9, 4.5, 1.5],\n",
      "       [6.1, 2.8, 4.7, 1.2],\n",
      "       [6.4, 2.8, 5.6, 2.1],\n",
      "       [4.9, 3.1, 1.5, 0.2],\n",
      "       [5.6, 2.9, 3.6, 1.3],\n",
      "       [5.9, 3. , 4.2, 1.5],\n",
      "       [6.3, 2.7, 4.9, 1.8],\n",
      "       [6.8, 3. , 5.5, 2.1],\n",
      "       [5.5, 2.3, 4. , 1.3]], dtype=float32)>, <tf.Tensor: shape=(16,), dtype=int32, numpy=array([2, 1, 1, 0, 2, 0, 0, 1, 1, 2, 0, 1, 1, 2, 2, 1])>)\n",
      "6 (<tf.Tensor: shape=(16, 4), dtype=float32, numpy=\n",
      "array([[6.3, 2.8, 5.1, 1.5],\n",
      "       [4.8, 3.4, 1.9, 0.2],\n",
      "       [6.3, 3.3, 4.7, 1.6],\n",
      "       [5.6, 2.5, 3.9, 1.1],\n",
      "       [5.1, 3.8, 1.9, 0.4],\n",
      "       [5.1, 3.8, 1.5, 0.3],\n",
      "       [4.6, 3.4, 1.4, 0.3],\n",
      "       [5.7, 2.8, 4.5, 1.3],\n",
      "       [6.6, 3. , 4.4, 1.4],\n",
      "       [5.1, 3.5, 1.4, 0.2],\n",
      "       [7.7, 3. , 6.1, 2.3],\n",
      "       [6.1, 3. , 4.9, 1.8],\n",
      "       [6.2, 2.2, 4.5, 1.5],\n",
      "       [6.3, 3.4, 5.6, 2.4],\n",
      "       [4.4, 3.2, 1.3, 0.2],\n",
      "       [6.5, 3.2, 5.1, 2. ]], dtype=float32)>, <tf.Tensor: shape=(16,), dtype=int32, numpy=array([2, 0, 1, 1, 0, 0, 0, 1, 1, 0, 2, 2, 1, 2, 0, 2])>)\n",
      "7 (<tf.Tensor: shape=(8, 4), dtype=float32, numpy=\n",
      "array([[5.5, 2.5, 4. , 1.3],\n",
      "       [6.3, 2.5, 4.9, 1.5],\n",
      "       [5.1, 3.3, 1.7, 0.5],\n",
      "       [5.8, 2.7, 5.1, 1.9],\n",
      "       [5.8, 2.6, 4. , 1.2],\n",
      "       [6.3, 2.9, 5.6, 1.8],\n",
      "       [5.8, 2.7, 4.1, 1. ],\n",
      "       [5. , 3. , 1.6, 0.2]], dtype=float32)>, <tf.Tensor: shape=(8,), dtype=int32, numpy=array([1, 1, 0, 2, 1, 2, 1, 0])>)\n"
     ]
    }
   ],
   "source": [
    "for a,b in enumerate(train_db):\n",
    "    print (a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, loss: 0.20058320462703705\n",
      "Test_acc: 0.6666666666666666\n",
      "--------------------------\n",
      "Epoch 1, loss: 0.1781129240989685\n",
      "Test_acc: 0.8333333333333334\n",
      "--------------------------\n",
      "Epoch 2, loss: 0.16099347360432148\n",
      "Test_acc: 0.8333333333333334\n",
      "--------------------------\n",
      "Epoch 3, loss: 0.14859094936400652\n",
      "Test_acc: 0.8333333333333334\n",
      "--------------------------\n",
      "Epoch 4, loss: 0.1395033122971654\n",
      "Test_acc: 0.8333333333333334\n",
      "--------------------------\n",
      "Epoch 5, loss: 0.1325981104746461\n",
      "Test_acc: 0.8\n",
      "--------------------------\n",
      "Epoch 6, loss: 0.12714260164648294\n",
      "Test_acc: 0.8\n",
      "--------------------------\n",
      "Epoch 7, loss: 0.12267694994807243\n",
      "Test_acc: 0.8\n",
      "--------------------------\n",
      "Epoch 8, loss: 0.11890869215130806\n",
      "Test_acc: 0.8\n",
      "--------------------------\n",
      "Epoch 9, loss: 0.11564698535948992\n",
      "Test_acc: 0.8\n",
      "--------------------------\n",
      "Epoch 10, loss: 0.11276376526802778\n",
      "Test_acc: 0.8\n",
      "--------------------------\n",
      "Epoch 11, loss: 0.11017071735113859\n",
      "Test_acc: 0.8\n",
      "--------------------------\n",
      "Epoch 12, loss: 0.10780544485896826\n",
      "Test_acc: 0.8\n",
      "--------------------------\n",
      "Epoch 13, loss: 0.10562280938029289\n",
      "Test_acc: 0.8\n",
      "--------------------------\n",
      "Epoch 14, loss: 0.10358954034745693\n",
      "Test_acc: 0.8\n",
      "--------------------------\n",
      "Epoch 15, loss: 0.10168060101568699\n",
      "Test_acc: 0.8\n",
      "--------------------------\n",
      "Epoch 16, loss: 0.09987688530236483\n",
      "Test_acc: 0.8333333333333334\n",
      "--------------------------\n",
      "Epoch 17, loss: 0.09816354420036077\n",
      "Test_acc: 0.8333333333333334\n",
      "--------------------------\n",
      "Epoch 18, loss: 0.0965289305895567\n",
      "Test_acc: 0.8333333333333334\n",
      "--------------------------\n",
      "Epoch 19, loss: 0.0949637396261096\n",
      "Test_acc: 0.8333333333333334\n",
      "--------------------------\n",
      "Epoch 20, loss: 0.09346046205610037\n",
      "Test_acc: 0.8666666666666667\n",
      "--------------------------\n",
      "Epoch 21, loss: 0.09201298654079437\n",
      "Test_acc: 0.8666666666666667\n",
      "--------------------------\n",
      "Epoch 22, loss: 0.09061628486961126\n",
      "Test_acc: 0.8666666666666667\n",
      "--------------------------\n",
      "Epoch 23, loss: 0.08926614746451378\n",
      "Test_acc: 0.8666666666666667\n",
      "--------------------------\n",
      "Epoch 24, loss: 0.08795905765146017\n",
      "Test_acc: 0.8666666666666667\n",
      "--------------------------\n",
      "Epoch 25, loss: 0.0866920156404376\n",
      "Test_acc: 0.8666666666666667\n",
      "--------------------------\n",
      "Epoch 26, loss: 0.08546244446188211\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 27, loss: 0.08426814340054989\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 28, loss: 0.08310716599225998\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 29, loss: 0.08197781536728144\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 30, loss: 0.08087858371436596\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 31, loss: 0.07980812340974808\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 32, loss: 0.07876520371064544\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 33, loss: 0.07774873357266188\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 34, loss: 0.07675770064815879\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 35, loss: 0.0757911647669971\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 36, loss: 0.07484827656298876\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 37, loss: 0.07392823649570346\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 38, loss: 0.07303028181195259\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 39, loss: 0.07215370982885361\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 40, loss: 0.07129785511642694\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 41, loss: 0.0704620722681284\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 42, loss: 0.06964576849713922\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 43, loss: 0.06884835660457611\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 44, loss: 0.06806927965953946\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 45, loss: 0.06730803567916155\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 46, loss: 0.06656408496201038\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 47, loss: 0.06583694089204073\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 48, loss: 0.06512614386156201\n",
      "Test_acc: 0.8666666666666667\n",
      "--------------------------\n",
      "Epoch 49, loss: 0.06443122634664178\n",
      "Test_acc: 0.8666666666666667\n",
      "--------------------------\n",
      "Epoch 50, loss: 0.06375175155699253\n",
      "Test_acc: 0.8666666666666667\n",
      "--------------------------\n",
      "Epoch 51, loss: 0.06308729201555252\n",
      "Test_acc: 0.8666666666666667\n",
      "--------------------------\n",
      "Epoch 52, loss: 0.06243742350488901\n",
      "Test_acc: 0.8666666666666667\n",
      "--------------------------\n",
      "Epoch 53, loss: 0.06180174555629492\n",
      "Test_acc: 0.8666666666666667\n",
      "--------------------------\n",
      "Epoch 54, loss: 0.06117987958714366\n",
      "Test_acc: 0.8666666666666667\n",
      "--------------------------\n",
      "Epoch 55, loss: 0.06057144049555063\n",
      "Test_acc: 0.8666666666666667\n",
      "--------------------------\n",
      "Epoch 56, loss: 0.05997606320306659\n",
      "Test_acc: 0.8666666666666667\n",
      "--------------------------\n",
      "Epoch 57, loss: 0.059393389616161585\n",
      "Test_acc: 0.8666666666666667\n",
      "--------------------------\n",
      "Epoch 58, loss: 0.05882308539003134\n",
      "Test_acc: 0.8666666666666667\n",
      "--------------------------\n",
      "Epoch 59, loss: 0.058264798019081354\n",
      "Test_acc: 0.8666666666666667\n",
      "--------------------------\n",
      "Epoch 60, loss: 0.057718219235539436\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 61, loss: 0.057183025404810905\n",
      "Test_acc: 0.9333333333333333\n",
      "--------------------------\n",
      "Epoch 62, loss: 0.056658919900655746\n",
      "Test_acc: 0.9333333333333333\n",
      "--------------------------\n",
      "Epoch 63, loss: 0.0561455856077373\n",
      "Test_acc: 0.9333333333333333\n",
      "--------------------------\n",
      "Epoch 64, loss: 0.05564274778589606\n",
      "Test_acc: 0.9333333333333333\n",
      "--------------------------\n",
      "Epoch 65, loss: 0.05515012703835964\n",
      "Test_acc: 0.9333333333333333\n",
      "--------------------------\n",
      "Epoch 66, loss: 0.054667450953274965\n",
      "Test_acc: 0.9333333333333333\n",
      "--------------------------\n",
      "Epoch 67, loss: 0.054194459691643715\n",
      "Test_acc: 0.9333333333333333\n",
      "--------------------------\n",
      "Epoch 68, loss: 0.05373088829219341\n",
      "Test_acc: 0.9333333333333333\n",
      "--------------------------\n",
      "Epoch 69, loss: 0.053276488557457924\n",
      "Test_acc: 0.9333333333333333\n",
      "--------------------------\n",
      "Epoch 70, loss: 0.05283102346584201\n",
      "Test_acc: 0.9333333333333333\n",
      "--------------------------\n",
      "Epoch 71, loss: 0.05239425925537944\n",
      "Test_acc: 0.9333333333333333\n",
      "--------------------------\n",
      "Epoch 72, loss: 0.05196596775203943\n",
      "Test_acc: 0.9333333333333333\n",
      "--------------------------\n",
      "Epoch 73, loss: 0.051545923575758934\n",
      "Test_acc: 0.9333333333333333\n",
      "--------------------------\n",
      "Epoch 74, loss: 0.0511339227668941\n",
      "Test_acc: 0.9333333333333333\n",
      "--------------------------\n",
      "Epoch 75, loss: 0.05072975065559149\n",
      "Test_acc: 0.9333333333333333\n",
      "--------------------------\n",
      "Epoch 76, loss: 0.050333206076174974\n",
      "Test_acc: 0.9333333333333333\n",
      "--------------------------\n",
      "Epoch 77, loss: 0.04994409531354904\n",
      "Test_acc: 0.9333333333333333\n",
      "--------------------------\n",
      "Epoch 78, loss: 0.04956222465261817\n",
      "Test_acc: 0.9333333333333333\n",
      "--------------------------\n",
      "Epoch 79, loss: 0.04918741248548031\n",
      "Test_acc: 0.9333333333333333\n",
      "--------------------------\n",
      "Epoch 80, loss: 0.048819477669894695\n",
      "Test_acc: 0.9333333333333333\n",
      "--------------------------\n",
      "Epoch 81, loss: 0.048458247911185026\n",
      "Test_acc: 0.9333333333333333\n",
      "--------------------------\n",
      "Epoch 82, loss: 0.04810355510562658\n",
      "Test_acc: 0.9333333333333333\n",
      "--------------------------\n",
      "Epoch 83, loss: 0.04775523976422846\n",
      "Test_acc: 0.9333333333333333\n",
      "--------------------------\n",
      "Epoch 84, loss: 0.04741312959231436\n",
      "Test_acc: 0.9333333333333333\n",
      "--------------------------\n",
      "Epoch 85, loss: 0.047077094204723835\n",
      "Test_acc: 0.9333333333333333\n",
      "--------------------------\n",
      "Epoch 86, loss: 0.04674696619622409\n",
      "Test_acc: 0.9333333333333333\n",
      "--------------------------\n",
      "Epoch 87, loss: 0.046422601910308\n",
      "Test_acc: 0.9333333333333333\n",
      "--------------------------\n",
      "Epoch 88, loss: 0.04610386281274259\n",
      "Test_acc: 0.9333333333333333\n",
      "--------------------------\n",
      "Epoch 89, loss: 0.045790609205141664\n",
      "Test_acc: 0.9333333333333333\n",
      "--------------------------\n",
      "Epoch 90, loss: 0.0454827097710222\n",
      "Test_acc: 0.9333333333333333\n",
      "--------------------------\n",
      "Epoch 91, loss: 0.04518003901466727\n",
      "Test_acc: 0.9333333333333333\n",
      "--------------------------\n",
      "Epoch 92, loss: 0.044882469112053514\n",
      "Test_acc: 0.9333333333333333\n",
      "--------------------------\n",
      "Epoch 93, loss: 0.04458988830447197\n",
      "Test_acc: 0.9333333333333333\n",
      "--------------------------\n",
      "Epoch 94, loss: 0.04430215968750417\n",
      "Test_acc: 0.9333333333333333\n",
      "--------------------------\n",
      "Epoch 95, loss: 0.04401916963979602\n",
      "Test_acc: 0.9333333333333333\n",
      "--------------------------\n",
      "Epoch 96, loss: 0.04374082735739648\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 97, loss: 0.04346700548194349\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 98, loss: 0.04319760692305863\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 99, loss: 0.04293252876959741\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 100, loss: 0.0426716732326895\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 101, loss: 0.04241493949666619\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 102, loss: 0.04216223140247166\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 103, loss: 0.04191347025334835\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 104, loss: 0.04166855267249048\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 105, loss: 0.04142739647068083\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 106, loss: 0.041189929470419884\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 107, loss: 0.040956055046990514\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 108, loss: 0.04072570288553834\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 109, loss: 0.04049878963269293\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 110, loss: 0.04027524613775313\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 111, loss: 0.0400550018530339\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 112, loss: 0.039837980177253485\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 113, loss: 0.03962411289103329\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 114, loss: 0.03941332851536572\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 115, loss: 0.03920557536184788\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 116, loss: 0.039000776363536716\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 117, loss: 0.038798883091658354\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 118, loss: 0.03859981382265687\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 119, loss: 0.03840352245606482\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 120, loss: 0.03820995520800352\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 121, loss: 0.0380190615542233\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 122, loss: 0.037830778397619724\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 123, loss: 0.03764504077844322\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 124, loss: 0.03746182075701654\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 125, loss: 0.037281055469065905\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 126, loss: 0.03710269392468035\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 127, loss: 0.03692669910378754\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 128, loss: 0.03675302187912166\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 129, loss: 0.036581605672836304\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 130, loss: 0.03641241113655269\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 131, loss: 0.03624540474265814\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 132, loss: 0.03608054923824966\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 133, loss: 0.035917764296755195\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 134, loss: 0.03575706225819886\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 135, loss: 0.03559837630018592\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 136, loss: 0.03544166963547468\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 137, loss: 0.035286912927404046\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 138, loss: 0.03513405518606305\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 139, loss: 0.03498306847177446\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 140, loss: 0.034833929501473904\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 141, loss: 0.034686596132814884\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 142, loss: 0.03454102762043476\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 143, loss: 0.03439721348695457\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 144, loss: 0.034255095990374684\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 145, loss: 0.034114659298211336\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 146, loss: 0.03397588059306145\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 147, loss: 0.033838704228401184\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 148, loss: 0.03370313229970634\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 149, loss: 0.03356911614537239\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 150, loss: 0.0334366406314075\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 151, loss: 0.033305675722658634\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 152, loss: 0.03317618556320667\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 153, loss: 0.03304816037416458\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 154, loss: 0.03292157407850027\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 155, loss: 0.03279639431275427\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 156, loss: 0.032672594068571925\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 157, loss: 0.0325501550687477\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 158, loss: 0.03242905845399946\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 159, loss: 0.032309279195033014\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 160, loss: 0.032190790749154985\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 161, loss: 0.03207358322106302\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 162, loss: 0.03195761621464044\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 163, loss: 0.03184289380442351\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 164, loss: 0.03172937931958586\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 165, loss: 0.031617058091796935\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 166, loss: 0.03150590567383915\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 167, loss: 0.03139591764193028\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 168, loss: 0.031287062796764076\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 169, loss: 0.031179322744719684\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 170, loss: 0.03107269073370844\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 171, loss: 0.030967140570282936\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 172, loss: 0.030862655257806182\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 173, loss: 0.030759224900975823\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 174, loss: 0.030656825052574277\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 175, loss: 0.030555447447113693\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 176, loss: 0.03045506787020713\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 177, loss: 0.03035568236373365\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 178, loss: 0.03025727136991918\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 179, loss: 0.030159819056279957\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 180, loss: 0.03006330446805805\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 181, loss: 0.029967724345624447\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 182, loss: 0.02987305831629783\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 183, loss: 0.029779296717606485\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 184, loss: 0.02968641824554652\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 185, loss: 0.02959443104919046\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 186, loss: 0.02950329298619181\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 187, loss: 0.02941301849205047\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 188, loss: 0.029323570779524744\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 189, loss: 0.029234967078082263\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 190, loss: 0.02914716419763863\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 191, loss: 0.02906016306951642\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 192, loss: 0.028973971609957516\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 193, loss: 0.028888549539260566\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 194, loss: 0.028803902096115053\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 195, loss: 0.02872001368086785\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 196, loss: 0.0286368754459545\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 197, loss: 0.02855448646005243\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 198, loss: 0.02847281051799655\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 199, loss: 0.028391860658302903\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 200, loss: 0.02831160614732653\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 201, loss: 0.02823206956963986\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 202, loss: 0.028153216000646353\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 203, loss: 0.028075037873350084\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 204, loss: 0.02799753553699702\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 205, loss: 0.02792069804854691\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 206, loss: 0.027844519587233663\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 207, loss: 0.02776897675357759\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 208, loss: 0.027694073738530278\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 209, loss: 0.02761980949435383\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 210, loss: 0.027546155848540366\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 211, loss: 0.02747311256825924\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 212, loss: 0.027400677441619337\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 213, loss: 0.02732883719727397\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 214, loss: 0.027257590438239276\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 215, loss: 0.027186927967704833\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 216, loss: 0.02711683278903365\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 217, loss: 0.027047308278270066\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 218, loss: 0.026978337089531124\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 219, loss: 0.026909920969046652\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 220, loss: 0.026842050603590906\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 221, loss: 0.02677472948562354\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 222, loss: 0.026707932469435036\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 223, loss: 0.02664165454916656\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 224, loss: 0.02657590212766081\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 225, loss: 0.026510672993026674\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 226, loss: 0.02644594630692154\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 227, loss: 0.026381718344055116\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 228, loss: 0.026317984447814524\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 229, loss: 0.026254732976667583\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 230, loss: 0.02619197149761021\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 231, loss: 0.026129686390049756\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 232, loss: 0.026067878701724112\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 233, loss: 0.026006525848060846\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 234, loss: 0.025945654255338013\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 235, loss: 0.02588520955760032\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 236, loss: 0.025825231452472508\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 237, loss: 0.025765703176148236\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 238, loss: 0.025706603890284896\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 239, loss: 0.025647939066402614\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 240, loss: 0.025589706376194954\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 241, loss: 0.025531896972097456\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 242, loss: 0.02547451772261411\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 243, loss: 0.025417543249204755\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 244, loss: 0.025360974832437932\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 245, loss: 0.025304818176664412\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 246, loss: 0.0252490610582754\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 247, loss: 0.025193705107085407\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 248, loss: 0.025138733792118728\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 249, loss: 0.02508416527416557\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 250, loss: 0.025029963697306812\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 251, loss: 0.024976150132715702\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 252, loss: 0.02492271165829152\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 253, loss: 0.024869634653441608\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 254, loss: 0.024816935299895704\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 255, loss: 0.02476460055913776\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 256, loss: 0.02471261622849852\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 257, loss: 0.024660989525727928\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 258, loss: 0.024609722779132426\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 259, loss: 0.024558789213187993\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 260, loss: 0.02450821327511221\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 261, loss: 0.02445797179825604\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 262, loss: 0.02440806885715574\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 263, loss: 0.024358496302738786\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 264, loss: 0.02430925180669874\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 265, loss: 0.02426033711526543\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 266, loss: 0.024211748968809843\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 267, loss: 0.024163480498827994\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 268, loss: 0.024115525069646537\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 269, loss: 0.024067880236543715\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 270, loss: 0.02402054436970502\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 271, loss: 0.023973530274815857\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 272, loss: 0.023926808964461088\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 273, loss: 0.023880380555056036\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 274, loss: 0.023834270308725536\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 275, loss: 0.023788425838574767\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 276, loss: 0.02374289825093001\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 277, loss: 0.023697649594396353\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 278, loss: 0.023652692150790244\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 279, loss: 0.02360799937741831\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 280, loss: 0.02356360707199201\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 281, loss: 0.023519488982856274\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 282, loss: 0.023475638357922435\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 283, loss: 0.02343206462683156\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 284, loss: 0.023388753237668425\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 285, loss: 0.023345722642261535\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 286, loss: 0.023302938207052648\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 287, loss: 0.023260429210495204\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 288, loss: 0.023218180460389704\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 289, loss: 0.023176166869234294\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 290, loss: 0.023134431918151677\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 291, loss: 0.023092938819900155\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 292, loss: 0.02305169781902805\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 293, loss: 0.023010701581370085\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 294, loss: 0.022969947836827487\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 295, loss: 0.022929435304831713\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 296, loss: 0.022889167710673064\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 297, loss: 0.02284913556650281\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 298, loss: 0.022809342364780605\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 299, loss: 0.022769779316149652\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 300, loss: 0.02273043995955959\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 301, loss: 0.022691343270707875\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 302, loss: 0.022652465500868857\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 303, loss: 0.022613814973738045\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 304, loss: 0.02257537975674495\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 305, loss: 0.022537175507750362\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 306, loss: 0.022499181563034654\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 307, loss: 0.022461413173004985\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 308, loss: 0.02242386300349608\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 309, loss: 0.02238651516381651\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 310, loss: 0.0223493839148432\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 311, loss: 0.022312458255328238\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 312, loss: 0.022275743598584086\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 313, loss: 0.022239231155253947\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 314, loss: 0.022202929249033332\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 315, loss: 0.02216682321159169\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 316, loss: 0.022130924102384597\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 317, loss: 0.022095214168075472\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 318, loss: 0.022059701557736844\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 319, loss: 0.02202438487438485\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 320, loss: 0.02198926394339651\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 321, loss: 0.021954338706564158\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 322, loss: 0.021919596823863685\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 323, loss: 0.02188504405785352\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 324, loss: 0.02185067831305787\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 325, loss: 0.021816499705892056\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 326, loss: 0.02178250515135005\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 327, loss: 0.02174868923611939\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 328, loss: 0.021715050272177905\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 329, loss: 0.021681597165297717\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 330, loss: 0.021648323978297412\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 331, loss: 0.021615220000967383\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 332, loss: 0.021582286048214883\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 333, loss: 0.021549538418184966\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 334, loss: 0.021516952547244728\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 335, loss: 0.02148453943664208\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 336, loss: 0.021452293556649238\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 337, loss: 0.021420213452074677\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 338, loss: 0.0213883159449324\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 339, loss: 0.021356559998821467\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 340, loss: 0.0213249740190804\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 341, loss: 0.021293564816005528\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 342, loss: 0.021262298163492233\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 343, loss: 0.021231190708931535\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 344, loss: 0.021200250484980643\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 345, loss: 0.021169463580008596\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 346, loss: 0.021138834999874234\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 347, loss: 0.021108346001710743\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 348, loss: 0.02107803284889087\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 349, loss: 0.021047857764642686\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 350, loss: 0.021017840190324932\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 351, loss: 0.020987960160709918\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 352, loss: 0.020958236360456795\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 353, loss: 0.020928653771989048\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 354, loss: 0.02089922351296991\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 355, loss: 0.02086993516422808\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 356, loss: 0.020840784127358347\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 357, loss: 0.020811787457205355\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 358, loss: 0.020782931533176452\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 359, loss: 0.02075421076733619\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 360, loss: 0.020725628884974867\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 361, loss: 0.02069718431448564\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 362, loss: 0.020668883458711207\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 363, loss: 0.020640713337343186\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 364, loss: 0.02061267982935533\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 365, loss: 0.020584787300322205\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 366, loss: 0.020557017356622964\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 367, loss: 0.02052937663393095\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 368, loss: 0.020501875260379165\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 369, loss: 0.020474504388403147\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 370, loss: 0.02044725726591423\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 371, loss: 0.02042014041217044\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 372, loss: 0.020393145736306906\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 373, loss: 0.020366286917123944\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 374, loss: 0.020339541195426136\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 375, loss: 0.020312937384005636\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 376, loss: 0.02028643590165302\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 377, loss: 0.02026006387313828\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 378, loss: 0.020233822928275913\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 379, loss: 0.020207686815410852\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 380, loss: 0.020181690517347306\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 381, loss: 0.020155799691565335\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 382, loss: 0.020130020275246352\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 383, loss: 0.020104371185880154\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 384, loss: 0.020078839384950697\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 385, loss: 0.020053411542903632\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 386, loss: 0.020028111117426306\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 387, loss: 0.020002918841782957\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 388, loss: 0.019977835298050195\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 389, loss: 0.019952861068304628\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 390, loss: 0.019928007968701422\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 391, loss: 0.01990326668601483\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 392, loss: 0.019878621853422374\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 393, loss: 0.019854100770317018\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 394, loss: 0.019829690572805703\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 395, loss: 0.0198053743224591\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 396, loss: 0.01978116756072268\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 397, loss: 0.019757072848733515\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 398, loss: 0.019733078486751765\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 399, loss: 0.019709194311872125\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 400, loss: 0.019685402687173337\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 401, loss: 0.01966172835091129\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 402, loss: 0.019638140278402716\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 403, loss: 0.01961467246292159\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 404, loss: 0.019591291551478207\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 405, loss: 0.019568016461562365\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 406, loss: 0.019544840150047094\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 407, loss: 0.019521764887031168\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 408, loss: 0.0194987915456295\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 409, loss: 0.019475898356176913\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 410, loss: 0.01945312204770744\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 411, loss: 0.019430432992521673\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 412, loss: 0.019407845858950168\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 413, loss: 0.01938533637439832\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 414, loss: 0.019362944818567485\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 415, loss: 0.01934063056251034\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 416, loss: 0.019318414037115872\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 417, loss: 0.0192962879082188\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 418, loss: 0.019274255901109427\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 419, loss: 0.019252317782957107\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 420, loss: 0.01923047105083242\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 421, loss: 0.019208705169148743\n",
      "Test_acc: 0.9\n",
      "--------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 422, loss: 0.01918702950933948\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 423, loss: 0.019165447796694934\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 424, loss: 0.01914395682979375\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 425, loss: 0.019122555502690375\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 426, loss: 0.019101236888673156\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 427, loss: 0.01907999679679051\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 428, loss: 0.019058862526435405\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 429, loss: 0.019037794321775436\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 430, loss: 0.01901681936578825\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 431, loss: 0.018995927996002138\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 432, loss: 0.018975126964505762\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 433, loss: 0.018954391649458557\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 434, loss: 0.01893375877989456\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 435, loss: 0.018913196108769625\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 436, loss: 0.01889272063272074\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 437, loss: 0.018872328684665263\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 438, loss: 0.018852015433367342\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 439, loss: 0.018831780937034637\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 440, loss: 0.018811627000104636\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 441, loss: 0.018791544251143932\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 442, loss: 0.018771549803204834\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 443, loss: 0.018751632538624108\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 444, loss: 0.018731791467871517\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 445, loss: 0.018712031713221222\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 446, loss: 0.0186923416913487\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 447, loss: 0.018672723905183375\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 448, loss: 0.0186531973304227\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 449, loss: 0.018633738392964005\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 450, loss: 0.01861434691818431\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 451, loss: 0.018595040310174227\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 452, loss: 0.01857580419164151\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 453, loss: 0.01855664636241272\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 454, loss: 0.01853755587944761\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 455, loss: 0.018518534896429628\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 456, loss: 0.018499582482036203\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 457, loss: 0.01848071429412812\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 458, loss: 0.018461913394276053\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 459, loss: 0.0184431784437038\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 460, loss: 0.018424516019877046\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 461, loss: 0.018405928916763514\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 462, loss: 0.018387402000371367\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 463, loss: 0.018368954595644027\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 464, loss: 0.018350567494053394\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 465, loss: 0.018332250823732466\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 466, loss: 0.018314007320441306\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 467, loss: 0.018295822839718312\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 468, loss: 0.01827771303942427\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 469, loss: 0.01825966202886775\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 470, loss: 0.018241688492707908\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 471, loss: 0.018223772349301726\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 472, loss: 0.018205925880465657\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 473, loss: 0.018188140878919512\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 474, loss: 0.01817042363109067\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 475, loss: 0.01815277145942673\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 476, loss: 0.018135177495423704\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 477, loss: 0.01811765629099682\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 478, loss: 0.0181001941091381\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 479, loss: 0.01808279799297452\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 480, loss: 0.01806545938597992\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 481, loss: 0.018048189056571573\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 482, loss: 0.01803097128868103\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 483, loss: 0.018013819120824337\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 484, loss: 0.017996736976783723\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 485, loss: 0.01797970215557143\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 486, loss: 0.017962734738830477\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 487, loss: 0.017945822823094204\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 488, loss: 0.017928978544659913\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 489, loss: 0.01791219928418286\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 490, loss: 0.01789546138024889\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 491, loss: 0.01787878284812905\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 492, loss: 0.017862173495814204\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 493, loss: 0.017845627415226772\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 494, loss: 0.017829128104494885\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 495, loss: 0.01781269200728275\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 496, loss: 0.01779631120734848\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 497, loss: 0.01777998814941384\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 498, loss: 0.017763714509783313\n",
      "Test_acc: 0.9\n",
      "--------------------------\n",
      "Epoch 499, loss: 0.017747504956787452\n",
      "Test_acc: 0.9\n",
      "--------------------------\n"
     ]
    }
   ],
   "source": [
    "## 定义网络结构\n",
    "w = tf.Variable(tf.random.truncated_normal([4,3],mean=0,stddev=0.1))  \n",
    "b = tf.Variable(tf.random.truncated_normal([3],mean=0,stddev=0.1))\n",
    "\n",
    "lr = 0.1\n",
    "epochs = 500\n",
    "train_loss_results = [] \n",
    "valid_acc = []\n",
    "loss_all = 0\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for step,(x_train,y_train) in enumerate(train_db):\n",
    "        with tf.GradientTape() as tape:\n",
    "            y = tf.nn.softmax(tf.matmul(x_train,w)+b)\n",
    "            y_ = tf.one_hot(y_train,depth=3)\n",
    "            loss = tf.reduce_mean(tf.square(y_ - y))\n",
    "            loss_all += loss.numpy()\n",
    "        grads = tape.gradient(loss,[w,b])\n",
    "        w.assign_sub(lr*grads[0] )\n",
    "        b.assign_sub(lr*grads[1])\n",
    "    print(\"Epoch {}, loss: {}\".format(epoch, loss_all/8))\n",
    "    train_loss_results.append(loss_all / 8) \n",
    "    loss_all = 0\n",
    "    \n",
    "    total_correct, total_number = 0, 0\n",
    "    \n",
    "    for x_valid, y_valid in valid_db:\n",
    "        y = tf.nn.softmax(tf.matmul(x_valid, w) + b)\n",
    "        pred = tf.argmax(y, axis=1) \n",
    "        pred = tf.cast(pred, dtype=y_valid.dtype)\n",
    "        correct = tf.cast(tf.equal(pred, y_valid), dtype=tf.int32)\n",
    "        correct = tf.reduce_sum(correct)\n",
    "        total_correct += int(correct)\n",
    "        total_number += x_valid.shape[0]    \n",
    "    acc = total_correct / total_number\n",
    "    valid_acc.append(acc)\n",
    "    print(\"Test_acc:\", acc)\n",
    "    print(\"--------------------------\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 绘制 loss 曲线\n",
    "plt.title('Loss Function Curve')  # 图片标题\n",
    "plt.xlabel('Epoch')  # x轴变量名称\n",
    "plt.ylabel('Loss')  # y轴变量名称\n",
    "plt.plot(train_loss_results, label=\"$Loss$\")  # 逐点画出trian_loss_results值并连线，连线图标是Loss\n",
    "plt.legend()  # 画出曲线图标\n",
    "plt.show()  # 画出图像\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# 绘制 Accuracy 曲线\n",
    "plt.title('Acc Curve')  # 图片标题\n",
    "plt.xlabel('Epoch')  # x轴变量名称\n",
    "plt.ylabel('Acc')  # y轴变量名称\n",
    "plt.plot(valid_acc, label=\"$Accuracy$\")  # 逐点画出test_acc值并连线，连线图标是Accuracy\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow2-gpu",
   "language": "python",
   "name": "tensorflow2-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
